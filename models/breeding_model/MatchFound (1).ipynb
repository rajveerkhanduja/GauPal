{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mAyewt2jKLn",
        "outputId": "553c7833-92bb-4724-9344-ecfad2363fff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 1. Install Libraries\n",
        "!pip install deap openpyxl scikit-learn --quiet\n",
        "print(\"Required libraries checked/installed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMICpavekNQM",
        "outputId": "c9aea910-ebe7-4a8a-c91d-aa907cc9457e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/135.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m133.1/135.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequired libraries checked/installed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 2. Import Libraries & Mount Google Drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import pickle\n",
        "import os\n",
        "import time\n",
        "import traceback # For detailed error printing\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, f1_score\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Import DEAP components after installation\n",
        "try:\n",
        "    from deap import base, creator, tools, algorithms\n",
        "except ImportError:\n",
        "    print(\"DEAP library not found after installation attempt. Please check installation.\")\n",
        "    raise SystemExit(\"DEAP required.\")\n",
        "\n",
        "\n",
        "print(\"Libraries imported.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InL6pR5dkW6c",
        "outputId": "748f0408-318b-4ea6-d644-4c63a007cc9c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 3. Define Data Path, Target Column, Threshold & Load Data\n",
        "\n",
        "# === Configuration ===\n",
        "# --- PATH TO YOUR *NEW* DATASET (with correct CCS score) ---\n",
        "data_path = '/content/drive/MyDrive/MatchFound.xlsx' # <--- *** REPLACE THIS PATH ***\n",
        "# --- NAME OF THE COLUMN WITH THE RAW CCS SCORE ---\n",
        "target_score_column = 'Compatibility_Score' # <--- *** VERIFY/CHANGE THIS COLUMN NAME ***\n",
        "# --- THRESHOLD FOR YES/NO CLASSIFICATION ---\n",
        "compatibility_threshold = 20 # <--- *** VERIFY/CHANGE THIS THRESHOLD ***\n",
        "# --- PATH TO SAVE FINAL MODEL COMPONENTS ---\n",
        "# Create the directory for saving if it doesn't exist\n",
        "model_save_directory = '/content/drive/MyDrive/MyModels' # Define directory\n",
        "model_save_path = os.path.join(model_save_directory, 'cattle_predictor_v2.pkl') # Define full path\n",
        "if not os.path.exists(model_save_directory):\n",
        "    print(f\"Creating save directory: {model_save_directory}\")\n",
        "    os.makedirs(model_save_directory)\n",
        "\n",
        "\n",
        "print(f\"Attempting to load data from: {data_path}\")\n",
        "if not os.path.exists(data_path):\n",
        "    print(f\"ERROR: File not found: {data_path}\"); raise SystemExit(\"Dataset not found.\")\n",
        "\n",
        "try:\n",
        "    df = pd.read_excel(data_path, engine='openpyxl')\n",
        "    print(f\"Dataset loaded successfully. Shape: {df.shape}\")\n",
        "    if target_score_column not in df.columns:\n",
        "        print(f\"ERROR: Target score column '{target_score_column}' not found!\")\n",
        "        print(f\"Available columns: {df.columns.tolist()}\")\n",
        "        raise SystemExit(\"Target column missing.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading XLSX: {e}\"); raise SystemExit(\"Data loading failed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvGFwbnBkdjQ",
        "outputId": "41b15ee6-da61-4fb3-d8a0-803336b916cc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to load data from: /content/drive/MyDrive/MatchFound.xlsx\n",
            "Dataset loaded successfully. Shape: (8000, 38)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 4. Create Targets & Define Features\n",
        "\n",
        "# Create Binary Classification Target\n",
        "binary_target_column = 'Compatible_Class'\n",
        "df[binary_target_column] = (df[target_score_column] >= compatibility_threshold).astype(int)\n",
        "\n",
        "print(f\"\\nCreated binary target '{binary_target_column}' based on threshold >= {compatibility_threshold}\")\n",
        "print(f\"Class distribution:\\n{df[binary_target_column].value_counts(normalize=True)}\")\n",
        "\n",
        "# Define Targets (y) and Features (X)\n",
        "y_reg = df[target_score_column]\n",
        "y_class = df[binary_target_column]\n",
        "\n",
        "# Ensure columns_to_exclude contains the correct target column name\n",
        "columns_to_exclude = [target_score_column, binary_target_column, 'Cow_ID', 'Bull_ID', 'Compatible'] # Add 'Compatible' if it exists from old versions\n",
        "# Check if 'Compatibility_Score' should also be excluded if it's different from target_score_column\n",
        "if 'Compatibility_Score' in df.columns and 'Compatibility_Score' != target_score_column:\n",
        "     columns_to_exclude.append('Compatibility_Score')\n",
        "\n",
        "columns_to_exclude = [col for col in columns_to_exclude if col in df.columns] # Keep only existing columns\n",
        "X = df.drop(columns=columns_to_exclude)\n",
        "\n",
        "print(f\"\\nFeatures (X shape): {X.shape}\")\n",
        "# print(\"Feature columns:\", X.columns.tolist()) # Uncomment to check features\n",
        "print(f\"Regression Target (y_reg shape): {y_reg.shape}\")\n",
        "print(f\"Classification Target (y_class shape): {y_class.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cgNN8SVkhK9",
        "outputId": "b88558db-f377-4759-c598-0ed6145b4f1a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Created binary target 'Compatible_Class' based on threshold >= 20\n",
            "Class distribution:\n",
            "Compatible_Class\n",
            "1    0.76675\n",
            "0    0.23325\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Features (X shape): (8000, 34)\n",
            "Regression Target (y_reg shape): (8000,)\n",
            "Classification Target (y_class shape): (8000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 5. Preprocessing Setup & Application\n",
        "\n",
        "# Identify feature types\n",
        "numerical_features = X.select_dtypes(include=np.number).columns.tolist()\n",
        "categorical_features = X.select_dtypes(exclude=np.number).columns.tolist()\n",
        "\n",
        "print(f\"\\nIdentified {len(numerical_features)} numerical features.\")\n",
        "print(f\"Identified {len(categorical_features)} categorical features.\")\n",
        "\n",
        "# Define preprocessing steps (using pipelines)\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='Missing')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))]) # handle_unknown is important\n",
        "\n",
        "# Create the preprocessor object\n",
        "# Ensure remainder='passthrough' only if you intend to keep non-numeric/non-categorical columns unprocessed\n",
        "# Usually, it's better to handle all columns explicitly. If X only contains num/cat, remainder='drop' is safer.\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)],\n",
        "    remainder='drop') # Drop columns not specified as numerical or categorical\n",
        "\n",
        "\n",
        "# Fit the preprocessor and transform the data *before* splitting\n",
        "print(\"\\nFitting preprocessor and transforming data...\")\n",
        "try:\n",
        "    X_processed = preprocessor.fit_transform(X)\n",
        "    print(\"Preprocessing complete.\")\n",
        "    # Get feature names after OneHotEncoding\n",
        "    try:\n",
        "        feature_names_out = preprocessor.get_feature_names_out()\n",
        "        print(f\"Total features after preprocessing: {len(feature_names_out)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Could not get feature names from preprocessor: {e}\")\n",
        "        num_processed_features = X_processed.shape[1]\n",
        "        feature_names_out = [f\"feature_{i}\" for i in range(num_processed_features)]\n",
        "        print(f\"Using generic feature names. Total features: {num_processed_features}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error during preprocessing fit_transform: {e}\")\n",
        "    traceback.print_exc()\n",
        "    raise SystemExit(\"Preprocessing failed.\")\n",
        "\n",
        "\n",
        "# Split PREPROCESSED data\n",
        "# Stratify ensures similar class distribution in train/test splits\n",
        "X_train_proc, X_test_proc, y_train_reg, y_test_reg, y_train_class, y_test_class = train_test_split(\n",
        "    X_processed, y_reg, y_class, test_size=0.25, random_state=42, stratify=y_class\n",
        ")\n",
        "\n",
        "print(f\"\\nData split after preprocessing:\")\n",
        "print(f\"X_train_proc shape: {X_train_proc.shape}, X_test_proc shape: {X_test_proc.shape}\")\n",
        "print(f\"y_train_class distribution:\\n{y_train_class.value_counts(normalize=True)}\")\n",
        "print(f\"y_test_class distribution:\\n{y_test_class.value_counts(normalize=True)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GcmVjAokjhg",
        "outputId": "c72c31c4-3c83-4a4a-dc8e-b63fed679926"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Identified 26 numerical features.\n",
            "Identified 8 categorical features.\n",
            "\n",
            "Fitting preprocessor and transforming data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['Bull_Milk_Yield']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing complete.\n",
            "Total features after preprocessing: 145\n",
            "\n",
            "Data split after preprocessing:\n",
            "X_train_proc shape: (6000, 145), X_test_proc shape: (2000, 145)\n",
            "y_train_class distribution:\n",
            "Compatible_Class\n",
            "1    0.766833\n",
            "0    0.233167\n",
            "Name: proportion, dtype: float64\n",
            "y_test_class distribution:\n",
            "Compatible_Class\n",
            "1    0.7665\n",
            "0    0.2335\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 6. Genetic Algorithm for Feature Selection Setup\n",
        "\n",
        "# --- GA Parameters ---\n",
        "N_FEATURES = X_train_proc.shape[1]\n",
        "# --- MODIFICATION: Increased GA Parameters ---\n",
        "POP_SIZE_FS = 80   # Increased Population size (was 50)\n",
        "NGEN_FS = 30       # Increased Number of generations (was 20)\n",
        "# --- End Modification ---\n",
        "CXPB_FS = 0.6      # Crossover probability\n",
        "MUTPB_FS = 0.2     # Mutation probability (for an individual)\n",
        "# Fitness function weights (adjust based on priority)\n",
        "WEIGHT_CLASSIFICATION = 0.5\n",
        "WEIGHT_REGRESSION = 0.5\n",
        "\n",
        "# --- Fitness Function ---\n",
        "# Calculate std dev of regression target once for normalization\n",
        "y_train_reg_std = y_train_reg.std()\n",
        "if y_train_reg_std == 0: y_train_reg_std = 1 # Avoid division by zero\n",
        "\n",
        "def evaluate_feature_subset(individual, X_data, y_reg_data, y_class_data, y_reg_std_dev):\n",
        "    \"\"\"Fitness function for GA Feature Selection.\"\"\"\n",
        "    selected_indices = [i for i, bit in enumerate(individual) if bit == 1]\n",
        "\n",
        "    if not selected_indices: return (0.0,)\n",
        "\n",
        "    X_subset = X_data[:, selected_indices]\n",
        "\n",
        "    # --- Evaluate Classifier (CV) ---\n",
        "    try:\n",
        "        # Use slightly faster settings for CV during fitness eval\n",
        "        clf = RandomForestClassifier(n_estimators=25, random_state=42, n_jobs=2, max_depth=8, min_samples_leaf=5)\n",
        "        class_scores = cross_val_score(clf, X_subset, y_class_data, cv=3, scoring='f1_weighted', n_jobs=2) # Use 2 jobs for CV\n",
        "        avg_class_score = np.mean(class_scores)\n",
        "    except ValueError: # Handles cases where a split might have only one class\n",
        "         avg_class_score = 0.0\n",
        "    except Exception as e_clf:\n",
        "        # print(f\"Classifier CV Error: {e_clf}\") # Optional debug\n",
        "        avg_class_score = 0.0\n",
        "\n",
        "    # --- Evaluate Regressor (CV) ---\n",
        "    try:\n",
        "        # Use slightly faster settings for CV during fitness eval\n",
        "        reg = RandomForestRegressor(n_estimators=25, random_state=42, n_jobs=2, max_depth=8, min_samples_leaf=5)\n",
        "        reg_scores = cross_val_score(reg, X_subset, y_reg_data, cv=3, scoring='neg_root_mean_squared_error', n_jobs=2) # Use 2 jobs for CV\n",
        "        avg_rmse = -np.mean(reg_scores)\n",
        "        normalized_rmse = avg_rmse / y_reg_std_dev if y_reg_std_dev > 0 else avg_rmse\n",
        "        reg_fitness_comp = max(0.0, 1.0 - normalized_rmse)\n",
        "    except Exception as e_reg:\n",
        "        # print(f\"Regressor CV Error: {e_reg}\") # Optional debug\n",
        "        reg_fitness_comp = 0.0\n",
        "\n",
        "    # --- Combine Scores ---\n",
        "    combined_fitness = (WEIGHT_CLASSIFICATION * avg_class_score) + \\\n",
        "                       (WEIGHT_REGRESSION * reg_fitness_comp)\n",
        "\n",
        "    return (combined_fitness,)\n",
        "\n",
        "# --- DEAP Setup for Feature Selection (Binary Individuals) ---\n",
        "# Clear previous creations if re-running cell\n",
        "if \"FitnessMaxFS\" in creator.__dict__: del creator.FitnessMaxFS\n",
        "if \"IndividualFS\" in creator.__dict__: del creator.IndividualFS\n",
        "\n",
        "creator.create(\"FitnessMaxFS\", base.Fitness, weights=(1.0,)) # Maximize combined score\n",
        "creator.create(\"IndividualFS\", list, fitness=creator.FitnessMaxFS) # Individual is list of 0s/1s\n",
        "\n",
        "toolbox_fs = base.Toolbox()\n",
        "toolbox_fs.register(\"attr_bool\", random.randint, 0, 1)\n",
        "toolbox_fs.register(\"individual\", tools.initRepeat, creator.IndividualFS, toolbox_fs.attr_bool, N_FEATURES)\n",
        "toolbox_fs.register(\"population\", tools.initRepeat, list, toolbox_fs.individual)\n",
        "toolbox_fs.register(\"evaluate\", evaluate_feature_subset,\n",
        "                    X_data=X_train_proc,\n",
        "                    y_reg_data=y_train_reg,\n",
        "                    y_class_data=y_train_class,\n",
        "                    y_reg_std_dev=y_train_reg_std)\n",
        "toolbox_fs.register(\"mate\", tools.cxUniform, indpb=0.5)\n",
        "toolbox_fs.register(\"mutate\", tools.mutFlipBit, indpb=0.05) # Prob per bit\n",
        "toolbox_fs.register(\"select\", tools.selTournament, tournsize=3)\n",
        "\n",
        "print(\"\\nDEAP toolbox for Feature Selection configured.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLVn7bt8koIH",
        "outputId": "0bfd8aa3-6f2a-426c-c20d-49cc9faffd3e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DEAP toolbox for Feature Selection configured.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 7. Run GA for Feature Selection\n",
        "\n",
        "print(f\"\\nStarting GA Feature Selection: Population={POP_SIZE_FS}, Generations={NGEN_FS}\")\n",
        "start_time_fs = time.time()\n",
        "\n",
        "pop_fs = toolbox_fs.population(n=POP_SIZE_FS)\n",
        "hof_fs = tools.HallOfFame(1) # Keep only the best\n",
        "\n",
        "stats_fs = tools.Statistics(lambda ind: ind.fitness.values)\n",
        "stats_fs.register(\"avg\", np.mean)\n",
        "stats_fs.register(\"std\", np.std)\n",
        "stats_fs.register(\"min\", np.min)\n",
        "stats_fs.register(\"max\", np.max)\n",
        "\n",
        "# Run the GA\n",
        "try:\n",
        "    algorithms.eaSimple(pop_fs, toolbox_fs, cxpb=CXPB_FS, mutpb=MUTPB_FS, ngen=NGEN_FS,\n",
        "                        stats=stats_fs, halloffame=hof_fs, verbose=True)\n",
        "except Exception as e_ga:\n",
        "    print(f\"Error during GA execution: {e_ga}\")\n",
        "    traceback.print_exc()\n",
        "    raise SystemExit(\"GA failed.\")\n",
        "\n",
        "\n",
        "end_time_fs = time.time()\n",
        "print(f\"GA Feature Selection finished in {end_time_fs - start_time_fs:.2f} seconds.\")\n",
        "\n",
        "# --- Extract Best Feature Set ---\n",
        "if len(hof_fs) == 0:\n",
        "     print(\"ERROR: HallOfFame is empty. GA might not have run correctly or found any valid individuals.\")\n",
        "     # Fallback: Use all features if GA fails? Or stop?\n",
        "     # selected_feature_indices = list(range(N_FEATURES)) # Option: Use all\n",
        "     raise SystemExit(\"GA did not produce a best individual.\")\n",
        "else:\n",
        "    best_individual_fs = hof_fs[0]\n",
        "    selected_feature_indices = [i for i, bit in enumerate(best_individual_fs) if bit == 1]\n",
        "    if not selected_feature_indices:\n",
        "        print(\"WARNING: GA selected zero features. Fitness function or GA parameters might need tuning. Using all features as fallback.\")\n",
        "        selected_feature_indices = list(range(N_FEATURES)) # Fallback to all features\n",
        "    else:\n",
        "         selected_feature_names = [feature_names_out[i] for i in selected_feature_indices]\n",
        "         print(f\"\\nGA selected {len(selected_feature_indices)} features out of {N_FEATURES}.\")\n",
        "         # print(\"Selected feature names:\", selected_feature_names) # Optional"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRfl21guktaH",
        "outputId": "4b12dee0-92f9-4d22-9437-4e2519c5e370"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting GA Feature Selection: Population=80, Generations=30\n",
            "gen\tnevals\tavg     \tstd     \tmin     \tmax    \n",
            "0  \t80    \t0.407367\t0.048741\t0.341118\t0.50019\n",
            "1  \t55    \t0.444584\t0.0448656\t0.35882 \t0.504514\n",
            "2  \t53    \t0.478191\t0.0275316\t0.393145\t0.503519\n",
            "3  \t62    \t0.491292\t0.0157661\t0.402939\t0.510553\n",
            "4  \t56    \t0.489898\t0.0238132\t0.389221\t0.504431\n",
            "5  \t55    \t0.497751\t0.00419147\t0.48849 \t0.508599\n",
            "6  \t56    \t0.497397\t0.0120198 \t0.398392\t0.509158\n",
            "7  \t61    \t0.499267\t0.01184   \t0.408951\t0.513735\n",
            "8  \t40    \t0.501524\t0.0114537 \t0.407416\t0.513735\n",
            "9  \t59    \t0.5016  \t0.0119445 \t0.402569\t0.513735\n",
            "10 \t56    \t0.500648\t0.018493  \t0.373412\t0.517385\n",
            "11 \t64    \t0.502733\t0.0155467 \t0.376833\t0.514163\n",
            "12 \t51    \t0.505247\t0.00672559\t0.466351\t0.516157\n",
            "13 \t57    \t0.504267\t0.0165759 \t0.410118\t0.516157\n",
            "14 \t47    \t0.505227\t0.0179147 \t0.401243\t0.516157\n",
            "15 \t51    \t0.508916\t0.00540433\t0.496442\t0.518298\n",
            "16 \t56    \t0.507663\t0.0162916 \t0.370052\t0.516157\n",
            "17 \t63    \t0.508024\t0.0136098 \t0.405415\t0.516157\n",
            "18 \t51    \t0.509368\t0.00561466\t0.492782\t0.520834\n",
            "19 \t62    \t0.506128\t0.0172956 \t0.409033\t0.520834\n",
            "20 \t61    \t0.501978\t0.0277614 \t0.374091\t0.520567\n",
            "21 \t61    \t0.507938\t0.0134258 \t0.410403\t0.520567\n",
            "22 \t57    \t0.507434\t0.0142938 \t0.395639\t0.51864 \n",
            "23 \t60    \t0.506883\t0.018243  \t0.395668\t0.524196\n",
            "24 \t42    \t0.509921\t0.0130507 \t0.40391 \t0.518761\n",
            "25 \t56    \t0.506977\t0.0215261 \t0.400559\t0.519678\n",
            "26 \t53    \t0.507539\t0.0190259 \t0.401305\t0.519678\n",
            "27 \t57    \t0.508462\t0.0190549 \t0.394208\t0.519678\n",
            "28 \t57    \t0.507931\t0.0220981 \t0.398148\t0.520588\n",
            "29 \t58    \t0.509506\t0.0187183 \t0.402617\t0.522297\n",
            "30 \t38    \t0.510835\t0.0198728 \t0.398339\t0.522297\n",
            "GA Feature Selection finished in 4572.97 seconds.\n",
            "\n",
            "GA selected 50 features out of 145.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 8. Train Final Models using Selected Features\n",
        "\n",
        "print(\"\\n--- Training Final Models on Selected Features ---\")\n",
        "\n",
        "# Select the best features from the training and test sets\n",
        "try:\n",
        "    X_train_selected = X_train_proc[:, selected_feature_indices]\n",
        "    X_test_selected = X_test_proc[:, selected_feature_indices]\n",
        "    print(f\"X_train_selected shape: {X_train_selected.shape}\")\n",
        "    print(f\"X_test_selected shape: {X_test_selected.shape}\")\n",
        "except IndexError as e_idx:\n",
        "     print(f\"Error selecting features with indices: {e_idx}\")\n",
        "     print(f\"Selected indices: {selected_feature_indices}\")\n",
        "     print(f\"X_train_proc shape: {X_train_proc.shape}\")\n",
        "     raise SystemExit(\"Feature selection failed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbwxdyrIkwuO",
        "outputId": "ffa2dd3d-47c4-4425-e30e-f2076cde05a0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training Final Models on Selected Features ---\n",
            "X_train_selected shape: (6000, 50)\n",
            "X_test_selected shape: (2000, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Train Final Classifier ---\n",
        "# Use more robust parameters for the final models\n",
        "final_classifier = RandomForestClassifier(n_estimators=150, # Increased estimators\n",
        "                                         random_state=42,\n",
        "                                         n_jobs=-1,\n",
        "                                         max_depth=18,     # Slightly deeper\n",
        "                                         min_samples_split=8, # Adjusted\n",
        "                                         min_samples_leaf=4,  # Added min_samples_leaf\n",
        "                                         class_weight='balanced' # Add class weighting if data is imbalanced\n",
        "                                         )\n",
        "print(\"Training final classifier...\")\n",
        "final_classifier.fit(X_train_selected, y_train_class)\n",
        "print(\"Classifier training complete.\")\n",
        "\n",
        "# --- Train Final Regressor ---\n",
        "final_regressor = RandomForestRegressor(n_estimators=150, # Increased estimators\n",
        "                                        random_state=42,\n",
        "                                        n_jobs=-1,\n",
        "                                        max_depth=18,    # Slightly deeper\n",
        "                                        min_samples_split=8, # Adjusted\n",
        "                                        min_samples_leaf=4   # Added min_samples_leaf\n",
        "                                        )\n",
        "print(\"Training final regressor...\")\n",
        "final_regressor.fit(X_train_selected, y_train_reg)\n",
        "print(\"Regressor training complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6izWLkVkzIY",
        "outputId": "6663334b-3eec-48e9-a0b2-1f26733c4cd2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training final classifier...\n",
            "Classifier training complete.\n",
            "Training final regressor...\n",
            "Regressor training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error\n"
      ],
      "metadata": {
        "id": "9ZjV-Nc33kKc"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 9. Evaluate Final Models\n",
        "\n",
        "print(\"\\n--- Evaluating Final CLASSIFIER on Test Set (Selected Features) ---\")\n",
        "try:\n",
        "    y_pred_class = final_classifier.predict(X_test_selected)\n",
        "    accuracy = accuracy_score(y_test_class, y_pred_class)\n",
        "    f1 = f1_score(y_test_class, y_pred_class, average='weighted')\n",
        "    print(f\"Classifier Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Classifier Weighted F1-Score: {f1:.4f}\")\n",
        "    # from sklearn.metrics import classification_report, confusion_matrix\n",
        "    # print(classification_report(y_test_class, y_pred_class))\n",
        "    # print(confusion_matrix(y_test_class, y_pred_class))\n",
        "except Exception as e_eval_clf:\n",
        "    print(f\"Error during classifier evaluation: {e_eval_clf}\")\n",
        "\n",
        "\n",
        "print(\"\\n--- Evaluating Final REGRESSOR on Test Set (Selected Features) ---\")\n",
        "try:\n",
        "    y_pred_reg = final_regressor.predict(X_test_selected)\n",
        "    r2 = r2_score(y_test_reg, y_pred_reg)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test_reg, y_pred_reg))\n",
        "    mae = mean_absolute_error(y_test_reg, y_pred_reg)\n",
        "    print(f\"Regressor R-squared (R²): {r2:.4f}\")\n",
        "    print(f\"Regressor Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
        "    print(f\"Regressor Mean Absolute Error (MAE): {mae:.4f}\")\n",
        "except Exception as e_eval_reg:\n",
        "     print(f\"Error during regressor evaluation: {e_eval_reg}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYDXok2ek1_Z",
        "outputId": "12df1230-5126-441b-f025-9863d42def3c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluating Final CLASSIFIER on Test Set (Selected Features) ---\n",
            "Classifier Accuracy: 0.8285\n",
            "Classifier Weighted F1-Score: 0.8217\n",
            "\n",
            "--- Evaluating Final REGRESSOR on Test Set (Selected Features) ---\n",
            "Regressor R-squared (R²): 0.5940\n",
            "Regressor Root Mean Squared Error (RMSE): 4.6490\n",
            "Regressor Mean Absolute Error (MAE): 3.7374\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 10. Save Components & Define Prediction Function\n",
        "\n",
        "# --- Define Min/Max for Percentage Conversion ---\n",
        "# Verify these based on your ACTUAL calculate_ccs function logic\n",
        "THEORETICAL_MIN_CCS = -50 # Example value\n",
        "THEORETICAL_MAX_CCS = 85  # Example value\n",
        "\n",
        "def convert_ccs_to_percentage(ccs_score, min_ccs=THEORETICAL_MIN_CCS, max_ccs=THEORETICAL_MAX_CCS):\n",
        "    \"\"\"Converts a raw CCS score to a percentage (0-100).\"\"\"\n",
        "    if max_ccs == min_ccs: return 50.0\n",
        "    clipped_score = np.clip(ccs_score, min_ccs, max_ccs)\n",
        "    percentage = ((clipped_score - min_ccs) / (max_ccs - min_ccs)) * 100\n",
        "    return percentage\n"
      ],
      "metadata": {
        "id": "85M2yMlgk5y0"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Save Model Components ---\n",
        "# Saving preprocessor, selected indices, classifier, regressor, scale factors, threshold\n",
        "save_components = {\n",
        "    'preprocessor': preprocessor,\n",
        "    'selected_feature_indices': selected_feature_indices,\n",
        "    'classifier': final_classifier,\n",
        "    'regressor': final_regressor,\n",
        "    'min_ccs': THEORETICAL_MIN_CCS,\n",
        "    'max_ccs': THEORETICAL_MAX_CCS,\n",
        "    'compatibility_threshold': compatibility_threshold\n",
        "}\n",
        "\n",
        "# Ensure directory exists (defined earlier) before saving\n",
        "try:\n",
        "    with open(model_save_path, 'wb') as f:\n",
        "        pickle.dump(save_components, f)\n",
        "    print(f\"\\nModel components saved successfully to Google Drive: {model_save_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nError saving model components: {e}\")\n",
        "\n",
        "\n",
        "# --- Load Model Function Definition ---\n",
        "def load_combined_model(filepath):\n",
        "    \"\"\"Loads the saved model components.\"\"\"\n",
        "    if not os.path.exists(filepath):\n",
        "        print(f\"ERROR: Model file not found at {filepath}\")\n",
        "        return None\n",
        "    try:\n",
        "        with open(filepath, 'rb') as f:\n",
        "            components = pickle.load(f)\n",
        "        print(f\"Model components loaded successfully from {filepath}\")\n",
        "        return components\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model components: {e}\")\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "\n",
        "# --- Prediction Function Definition ---\n",
        "def predict_cattle_compatibility(new_data_df, model_components):\n",
        "    \"\"\"\n",
        "    Predicts Yes/No compatibility and percentage score for new cattle data.\n",
        "    \"\"\"\n",
        "    if model_components is None:\n",
        "        print(\"ERROR: Model components not loaded.\"); return None\n",
        "\n",
        "    try:\n",
        "        # Extract components\n",
        "        preprocessor = model_components['preprocessor']\n",
        "        selected_indices = model_components['selected_feature_indices']\n",
        "        classifier = model_components['classifier']\n",
        "        regressor = model_components['regressor']\n",
        "        min_ccs = model_components['min_ccs']\n",
        "        max_ccs = model_components['max_ccs']\n",
        "\n",
        "        # 1. Preprocess the new data\n",
        "        # Ensure input df has columns expected by preprocessor\n",
        "        # Handle potential errors during transform\n",
        "        try:\n",
        "             X_new_processed = preprocessor.transform(new_data_df)\n",
        "        except ValueError as ve:\n",
        "             print(f\"ValueError during preprocessing transform: {ve}\")\n",
        "             print(\"Ensure input DataFrame columns exactly match those used during preprocessor fitting.\")\n",
        "             # Optionally try to get expected columns:\n",
        "             # if hasattr(preprocessor, 'feature_names_in_'):\n",
        "             #      print(\"Preprocessor expected columns:\", preprocessor.feature_names_in_)\n",
        "             # else:\n",
        "             #      # Need to infer expected columns from transformers if possible\n",
        "             #      pass\n",
        "             return None\n",
        "        except Exception as e_prep:\n",
        "            print(f\"Error during preprocessing transform: {e_prep}\")\n",
        "            traceback.print_exc()\n",
        "            return None\n",
        "\n",
        "\n",
        "        # 2. Select the features identified by the GA\n",
        "        try:\n",
        "             X_new_selected = X_new_processed[:, selected_indices]\n",
        "        except IndexError as e_idx_pred:\n",
        "             print(f\"Error selecting features during prediction: {e_idx_pred}\")\n",
        "             print(f\"Processed data shape: {X_new_processed.shape}, Selected indices count: {len(selected_indices)}\")\n",
        "             return None\n",
        "\n",
        "\n",
        "        # 3. Predict Class (0/1)\n",
        "        class_predictions = classifier.predict(X_new_selected)\n",
        "\n",
        "        # 4. Predict Raw CCS Score\n",
        "        ccs_predictions = regressor.predict(X_new_selected)\n",
        "\n",
        "        # 5. Convert CCS to Percentage\n",
        "        percentage_predictions = [convert_ccs_to_percentage(score, min_ccs, max_ccs) for score in ccs_predictions]\n",
        "\n",
        "        # 6. Format Output\n",
        "        results = []\n",
        "        for i in range(len(class_predictions)):\n",
        "            prediction_label = \"Yes\" if class_predictions[i] == 1 else \"No\"\n",
        "            results.append({\n",
        "                \"Prediction\": prediction_label,\n",
        "                \"Confidence_Score_Percent\": round(percentage_predictions[i], 2),\n",
        "                \"Raw_CCS_Score\": round(ccs_predictions[i], 2)\n",
        "            })\n",
        "        return results\n",
        "\n",
        "    except Exception as e_pred:\n",
        "        print(f\"An error occurred during prediction steps: {e_pred}\")\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "print(\"\\nHelper functions for loading and prediction defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_Bfnxk3k_UG",
        "outputId": "8bf79ded-6d67-4173-aa6a-feeb75a9754f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model components saved successfully to Google Drive: /content/drive/MyDrive/MyModels/cattle_predictor_v2.pkl\n",
            "\n",
            "Helper functions for loading and prediction defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 11. Example Usage\n",
        "\n",
        "print(\"\\n--- Loading saved model and predicting on dummy data ---\")\n",
        "loaded_model = load_combined_model(model_save_path)\n",
        "\n",
        "if loaded_model:\n",
        "    # Create dummy data - MUST match columns of original X BEFORE preprocessing\n",
        "    # Example using minimal representative data\n",
        "    dummy_data = {\n",
        "        # --- Numerical ---\n",
        "        'Cow_Age': [5, 7], 'Cow_Weight': [550.0, 610.0], 'Cow_Height': [130.0, 138.0],\n",
        "        'Cow_Milk_Yield': [8.5, 7.0], 'Cow_Genetic_Diversity_Score': [7.5, 6.8],\n",
        "        'Cow_Fertility_Rate': [60.0, 75.0], 'Cow_Breeding_Success_Rate': [50.0, 65.0],\n",
        "        'Cow_Drought_Resistance': [70.0, 55.0], 'Cow_Disease_Resistance_Score': [6.0, 7.2],\n",
        "        'Cow_Market_Value': [15000, 21000], 'Cow_Mother_Milk_Yield': [7.0, 8.1],\n",
        "        'Bull_Age': [4, 6], 'Bull_Weight': [650.0, 710.0], 'Bull_Height': [145.0, 152.0],\n",
        "        'Bull_Milk_Yield': [np.nan, np.nan], # Use NaN if typically missing\n",
        "        'Bull_Genetic_Diversity_Score': [8.0, 7.1], 'Bull_Fertility_Rate': [70.0, 65.0],\n",
        "        'Bull_Breeding_Success_Rate': [60.0, 55.0], 'Bull_Drought_Resistance': [80.0, 60.0],\n",
        "        'Bull_Disease_Resistance_Score': [7.5, 6.8], 'Bull_Market_Value': [20000, 19000],\n",
        "        'Bull_Mother_Milk_Yield': [np.nan, np.nan], # Use NaN if typically missing\n",
        "        # --- Categorical ---\n",
        "        'Cow_Breed': ['Angus', 'Brahman'], 'Cow_Health_Status': [0, 1], # Assuming numeric encoding used directly if applicable, else string\n",
        "        'Cow_Temperament': ['Calm', 'Aggressive'], 'Cow_Disease': ['FootRot', 'None'],\n",
        "        'Cow_Past_Breeding_Success': ['Moderate', 'High'], 'Cow_Same_Parents': [0, 1], # Assuming numeric\n",
        "        'Bull_Breed': ['Brahman', 'Angus'], 'Bull_Health_Status': [0, 0],\n",
        "        'Bull_Temperament': ['Aggressive', 'Calm'], 'Bull_Disease': ['None', 'BLV'],\n",
        "        'Bull_Past_Breeding_Success': ['High', 'Low'], 'Bull_Same_Parents': [0, 0],\n",
        "        # --- Features from your specific calculate_ccs if used as direct inputs ---\n",
        "        'Trait_Difference': [15, 22],  # Example\n",
        "        'Genetic_Diversity': [8.1, 6.5], # Example - Ensure names match columns in X\n",
        "        # Add *ALL* other columns present in X (before preprocessing) with dummy/NaN values\n",
        "    }\n",
        "\n",
        "    # --- Dynamically ensure all columns from training X are present ---\n",
        "    if 'preprocessor' in loaded_model:\n",
        "        try:\n",
        "            # Get expected feature names from the fitted preprocessor\n",
        "            if hasattr(loaded_model['preprocessor'], 'feature_names_in_'):\n",
        "                expected_cols = loaded_model['preprocessor'].feature_names_in_\n",
        "            else: # Fallback if feature_names_in_ not available (older sklearn?)\n",
        "                  # Infer from transformers if possible - this is more complex\n",
        "                  # For now, assume X used for fitting is available or handle error\n",
        "                 print(\"Warning: Cannot automatically determine expected columns from preprocessor.\")\n",
        "                 # You might need to manually define expected_cols based on your training X here\n",
        "                 expected_cols = list(X.columns) # Assuming X from Cell 4 is available (less robust)\n",
        "\n",
        "            print(f\"\\nPreprocessor expects {len(expected_cols)} columns.\")\n",
        "            dummy_df = pd.DataFrame(dummy_data) # Create initial DF\n",
        "\n",
        "            missing_in_dummy = [col for col in expected_cols if col not in dummy_df.columns]\n",
        "            if missing_in_dummy:\n",
        "                print(f\"Adding missing expected columns to dummy data: {missing_in_dummy}\")\n",
        "                for col in missing_in_dummy:\n",
        "                    dummy_df[col] = np.nan # Add missing columns with NaN\n",
        "\n",
        "            # Select and potentially reorder columns to match preprocessor's expectation\n",
        "            try:\n",
        "                dummy_df = dummy_df[expected_cols]\n",
        "                print(\"Dummy data columns aligned with preprocessor expectations.\")\n",
        "            except KeyError as e_key:\n",
        "                 print(f\"KeyError aligning dummy data columns: {e_key}. Check column names.\")\n",
        "                 dummy_df = None # Prevent prediction if alignment fails\n",
        "\n",
        "        except Exception as e_cols:\n",
        "             print(f\"Error preparing dummy data columns: {e_cols}\")\n",
        "             dummy_df = None\n",
        "    else:\n",
        "         print(\"ERROR: Preprocessor not found in loaded model components.\")\n",
        "         dummy_df = None\n",
        "\n",
        "    # --- Run Prediction if dummy data is ready ---\n",
        "    if dummy_df is not None:\n",
        "        predictions = predict_cattle_compatibility(dummy_df, loaded_model)\n",
        "\n",
        "        if predictions:\n",
        "            print(\"\\n--- Predictions for Dummy Data ---\")\n",
        "            results_df = pd.DataFrame(predictions)\n",
        "            print(results_df.to_string()) # Print full DataFrame results\n",
        "            # for i, result in enumerate(predictions):\n",
        "            #     print(f\"Pair {i+1}:\")\n",
        "            #     print(f\"  Prediction: {result['Prediction']}\")\n",
        "            #     print(f\"  Percentage Score: {result['Confidence_Score_Percent']}%\")\n",
        "            #     print(f\"  Predicted Raw CCS: {result['Raw_CCS_Score']}\")\n",
        "            #     print(\"-\" * 10)\n",
        "        else:\n",
        "            print(\"Prediction function returned None (failed).\")\n",
        "    else:\n",
        "         print(\"Dummy data preparation failed, skipping prediction.\")\n",
        "\n",
        "else:\n",
        "    print(\"Could not load model components to run prediction example.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_rGx7yGlAF0",
        "outputId": "c940003e-a3e8-44ca-f6d4-d2e5c57dec8e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Loading saved model and predicting on dummy data ---\n",
            "Model components loaded successfully from /content/drive/MyDrive/MyModels/cattle_predictor_v2.pkl\n",
            "\n",
            "Preprocessor expects 34 columns.\n",
            "Dummy data columns aligned with preprocessor expectations.\n",
            "\n",
            "--- Predictions for Dummy Data ---\n",
            "  Prediction  Confidence_Score_Percent  Raw_CCS_Score\n",
            "0        Yes                     63.28          35.42\n",
            "1        Yes                     57.22          27.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['Bull_Milk_Yield']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 9. Evaluate Final Models\n",
        "\n",
        "# --- This section calculates and prints the Classifier's Accuracy ---\n",
        "print(\"\\n--- Evaluating Final CLASSIFIER on Test Set (Selected Features) ---\")\n",
        "\n",
        "# 1. Predict class labels (0 or 1) on the test set using the selected features\n",
        "y_pred_class = final_classifier.predict(X_test_selected)\n",
        "\n",
        "# 2. Calculate accuracy by comparing predictions (y_pred_class) to the true labels (y_test_class)\n",
        "accuracy = accuracy_score(y_test_class, y_pred_class)\n",
        "\n",
        "# 3. Calculate F1-score (another useful classification metric)\n",
        "f1 = f1_score(y_test_class, y_pred_class, average='weighted')\n",
        "\n",
        "# 4. Print the results\n",
        "print(f\"Classifier Accuracy: {accuracy:.4f}\") # <-- THIS IS THE ACCURACY ON THE TEST SET\n",
        "print(f\"Classifier Weighted F1-Score: {f1:.4f}\")\n",
        "\n",
        "# Optional detailed report (currently commented out)\n",
        "# from sklearn.metrics import classification_report, confusion_matrix\n",
        "# print(classification_report(y_test_class, y_pred_class))\n",
        "# print(confusion_matrix(y_test_class, y_pred_class))\n",
        "\n",
        "\n",
        "# --- This section evaluates the Regressor (predicting the score) ---\n",
        "print(\"\\n--- Evaluating Final REGRESSOR on Test Set (Selected Features) ---\")\n",
        "# (Code for R², RMSE, MAE follows...)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2QpfziD3upf",
        "outputId": "978c26de-460a-479d-c705-7224337e5e48"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluating Final CLASSIFIER on Test Set (Selected Features) ---\n",
            "Classifier Accuracy: 0.8285\n",
            "Classifier Weighted F1-Score: 0.8217\n",
            "\n",
            "--- Evaluating Final REGRESSOR on Test Set (Selected Features) ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 11. Example Usage (with Added Sample Pair)\n",
        "\n",
        "import pandas as pd # Ensure pandas is imported in this scope if needed\n",
        "import numpy as np  # Ensure numpy is imported\n",
        "\n",
        "print(\"\\n--- Loading saved model and predicting on dummy data ---\")\n",
        "loaded_model = load_combined_model(model_save_path) # Assumes model_save_path is defined\n",
        "\n",
        "if loaded_model:\n",
        "    # --- Define the specific sample pair ---\n",
        "    sample_pair = {\n",
        "        'Cow': { 'Breed': 'Gir', 'Age': 6, 'Weight': 450, 'Height': 140, 'Milk_Yield': 8,\n",
        "                 'Health_Status': 0, 'Drought_Resistance': 70, 'Temperament': 'Calm',\n",
        "                 # Add other Cow keys expected by X, even if None/NaN in this sample\n",
        "                 'Genetic_Diversity_Score': np.nan, 'Fertility_Rate': np.nan, 'Breeding_Success_Rate': np.nan,\n",
        "                 'Disease_Resistance_Score': np.nan, 'Market_Value': np.nan, 'Mother_Milk_Yield': np.nan,\n",
        "                 'Disease': np.nan, 'Past_Breeding_Success': np.nan, 'Same_Parents': np.nan\n",
        "               },\n",
        "        'Bull': {'Breed': 'Jersey', 'Age': 7, 'Weight': 470, 'Height': 142, 'Health_Status': 0,\n",
        "                 'Mother_Milk_Yield': 9, 'Drought_Resistance': 75, 'Temperament': 'Calm',\n",
        "                 # Add other Bull keys expected by X, even if None/NaN in this sample\n",
        "                 'Milk_Yield': np.nan, 'Genetic_Diversity_Score': np.nan, 'Fertility_Rate': np.nan,\n",
        "                 'Breeding_Success_Rate': np.nan, 'Disease_Resistance_Score': np.nan, 'Market_Value': np.nan,\n",
        "                 'Disease': np.nan, 'Past_Breeding_Success': np.nan, 'Same_Parents': np.nan\n",
        "                },\n",
        "        # Top-level keys expected by X\n",
        "        'Same_Parents': 0,\n",
        "        'Trait_Difference': 18,\n",
        "        'Genetic_Diversity': 8, # This might override individual scores depending on how X was defined\n",
        "        'Fertility_Rate': 65,\n",
        "        'Breeding_Success_Rate': 55,\n",
        "        'Disease_Resistance_Score': 6.5,\n",
        "        'Market_Value': 25000,\n",
        "        'Past_Breeding_Success': 'High'\n",
        "    }\n",
        "\n",
        "    # --- Flatten the sample_pair into a dictionary matching DataFrame columns ---\n",
        "    flat_sample = {}\n",
        "    for prefix, inner_dict in sample_pair.items():\n",
        "        if isinstance(inner_dict, dict):\n",
        "            for key, value in inner_dict.items():\n",
        "                flat_sample[f\"{prefix}_{key}\"] = value\n",
        "        else:\n",
        "            # Handle top-level keys directly\n",
        "            flat_sample[prefix] = inner_dict\n",
        "\n",
        "    # Convert the flattened sample to a DataFrame row\n",
        "    new_pair_df = pd.DataFrame([flat_sample])\n",
        "    print(\"Flattened sample pair prepared.\")\n",
        "\n",
        "\n",
        "    # --- Create original dummy data ---\n",
        "    dummy_data = {\n",
        "        'Cow_Breed': ['Angus', 'Holstein', 'UnknownBreed'], 'Cow_Age': [5, 6, 7], 'Cow_Weight': [550.0, 600.0, 580.0],\n",
        "        'Cow_Height': [130.0, 140.0, 135.0], 'Cow_Milk_Yield': [8.5, 9.0, np.nan], 'Cow_Health_Status': [0, 1, 0],\n",
        "        'Cow_Genetic_Diversity_Score': [7.5, 8.1, 7.0], 'Cow_Fertility_Rate': [60.0, 65.0, 55.0],\n",
        "        'Cow_Breeding_Success_Rate': [50.0, 55.0, 45.0], 'Cow_Drought_Resistance': [70.0, 60.0, 65.0],\n",
        "        'Cow_Disease_Resistance_Score': [6.0, 7.0, 5.5], 'Cow_Market_Value': [15000, 18000, 16000],\n",
        "        'Cow_Temperament': ['Calm', 'Calm', 'Aggressive'], 'Cow_Mother_Milk_Yield': [7.0, 7.5, 6.5],\n",
        "        'Cow_Disease': ['FootRot', 'Mastitis', np.nan], 'Cow_Past_Breeding_Success': ['Moderate', 'High', 'Low'],\n",
        "        'Cow_Same_Parents': [0, 0, 1], # Note: This might conflict with top-level Same_Parents if kept\n",
        "        'Bull_Breed': ['Brahman', 'Angus', 'Brahman'], 'Bull_Age': [4, 5, 6], 'Bull_Weight': [650.0, 680.0, 700.0],\n",
        "        'Bull_Height': [145.0, 150.0, 155.0], 'Bull_Milk_Yield': [np.nan, np.nan, np.nan],\n",
        "        'Bull_Health_Status': [0, 0, 1], 'Bull_Genetic_Diversity_Score': [8.0, 7.8, 7.5],\n",
        "        'Bull_Fertility_Rate': [70.0, 75.0, 68.0], 'Bull_Breeding_Success_Rate': [60.0, 65.0, 58.0],\n",
        "        'Bull_Drought_Resistance': [80.0, 50.0, 75.0], 'Bull_Disease_Resistance_Score': [7.5, 6.5, 7.0],\n",
        "        'Bull_Market_Value': [20000, 22000, 21000], 'Bull_Temperament': ['Aggressive', 'Calm', 'Calm'],\n",
        "        'Bull_Mother_Milk_Yield': [np.nan, np.nan, np.nan], 'Bull_Disease': ['None', 'BLV', 'FootRot'],\n",
        "        'Bull_Past_Breeding_Success': ['High', 'Moderate', 'Moderate'],\n",
        "        'Bull_Same_Parents': [0, 1, 0], # Note: This might conflict with top-level Same_Parents if kept\n",
        "        # --- Top-level combined features (as used in Feature Engineering) ---\n",
        "        'Same_Parents': [0, 1, 0], # Example values matching number of rows\n",
        "        'Trait_Difference': [15, 25, 10],\n",
        "        'Genetic_Diversity': [8, 6, 7.5],\n",
        "        'Fertility_Rate': [65, 70, 60], # Example values\n",
        "        'Breeding_Success_Rate': [55, 60, 50], # Example values\n",
        "        'Disease_Resistance_Score': [6.5, 7.0, 6.0], # Example values\n",
        "        'Market_Value': [25000, 19000, 23000], # Example values\n",
        "        # Add *ALL* other columns present in X (before preprocessing)\n",
        "    }\n",
        "    original_dummy_df = pd.DataFrame(dummy_data)\n",
        "\n",
        "    # --- Concatenate the original dummy data and the new sample pair ---\n",
        "    combined_dummy_df = pd.concat([original_dummy_df, new_pair_df], ignore_index=True)\n",
        "    print(f\"Combined dummy data shape: {combined_dummy_df.shape}\")\n",
        "\n",
        "\n",
        "    # --- Dynamically ensure all columns from training X are present ---\n",
        "    final_dummy_df = None # Initialize\n",
        "    if 'preprocessor' in loaded_model:\n",
        "        try:\n",
        "            # Get expected feature names from the fitted preprocessor\n",
        "            if hasattr(loaded_model['preprocessor'], 'feature_names_in_'):\n",
        "                expected_cols = loaded_model['preprocessor'].feature_names_in_\n",
        "            else:\n",
        "                 print(\"Warning: Cannot automatically determine expected columns from preprocessor. Using columns from Cell 4's X.\")\n",
        "                 # This assumes 'X' from cell 4 is still available and correct. It's less robust.\n",
        "                 if 'X' in globals():\n",
        "                     expected_cols = list(X.columns)\n",
        "                 else:\n",
        "                     raise ValueError(\"Original X dataframe not available to determine expected columns.\")\n",
        "\n",
        "            print(f\"\\nPreprocessor expects {len(expected_cols)} columns for prediction.\")\n",
        "\n",
        "            # Check for missing columns in the combined dummy data\n",
        "            current_dummy_cols = combined_dummy_df.columns\n",
        "            missing_in_dummy = [col for col in expected_cols if col not in current_dummy_cols]\n",
        "            if missing_in_dummy:\n",
        "                print(f\"Adding missing expected columns to combined dummy data: {missing_in_dummy}\")\n",
        "                for col in missing_in_dummy:\n",
        "                    combined_dummy_df[col] = np.nan # Add missing columns with NaN\n",
        "\n",
        "            # Select and reorder columns to match preprocessor's expectation\n",
        "            try:\n",
        "                final_dummy_df = combined_dummy_df[expected_cols] # Ensure correct order and columns\n",
        "                print(\"Combined dummy data columns aligned with preprocessor expectations.\")\n",
        "            except KeyError as e_key:\n",
        "                 print(f\"KeyError aligning dummy data columns: {e_key}. Check column names in dummy data and expected columns.\")\n",
        "                 final_dummy_df = None # Prevent prediction if alignment fails\n",
        "            except Exception as e_align:\n",
        "                 print(f\"Error aligning dummy data columns: {e_align}\")\n",
        "                 final_dummy_df = None\n",
        "\n",
        "        except Exception as e_cols:\n",
        "             print(f\"Error preparing dummy data columns: {e_cols}\")\n",
        "             final_dummy_df = None\n",
        "    else:\n",
        "         print(\"ERROR: Preprocessor not found in loaded model components.\")\n",
        "         final_dummy_df = None\n",
        "\n",
        "    # --- Run Prediction if dummy data is ready ---\n",
        "    if final_dummy_df is not None:\n",
        "        predictions = predict_cattle_compatibility(final_dummy_df, loaded_model) # Use the final aligned df\n",
        "\n",
        "        if predictions:\n",
        "            print(\"\\n--- Predictions for Dummy Data (including added sample) ---\")\n",
        "            results_df = pd.DataFrame(predictions)\n",
        "            # Add an identifier column for clarity\n",
        "            results_df['Source'] = ['Dummy'] * len(original_dummy_df) + ['Added Sample'] * len(new_pair_df)\n",
        "            print(results_df.to_string()) # Print full DataFrame results\n",
        "        else:\n",
        "            print(\"Prediction function returned None (failed).\")\n",
        "    else:\n",
        "         print(\"Dummy data preparation failed, skipping prediction.\")\n",
        "\n",
        "else:\n",
        "    print(\"Could not load model components to run prediction example.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3NI2A8DAbmy",
        "outputId": "3c34271b-1c11-482e-b331-1070a081345c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Loading saved model and predicting on dummy data ---\n",
            "Model components loaded successfully from /content/drive/MyDrive/MyModels/cattle_predictor_v2.pkl\n",
            "Flattened sample pair prepared.\n",
            "Combined dummy data shape: (4, 42)\n",
            "\n",
            "Preprocessor expects 34 columns for prediction.\n",
            "Combined dummy data columns aligned with preprocessor expectations.\n",
            "\n",
            "--- Predictions for Dummy Data (including added sample) ---\n",
            "  Prediction  Confidence_Score_Percent  Raw_CCS_Score        Source\n",
            "0        Yes                     63.28          35.42         Dummy\n",
            "1        Yes                     62.02          33.72         Dummy\n",
            "2        Yes                     55.60          25.06         Dummy\n",
            "3        Yes                     61.05          32.42  Added Sample\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['Bull_Milk_Yield']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 11. Example Usage (with Added Sample Pair & More Detail)\n",
        "\n",
        "import pandas as pd # Ensure pandas is imported in this scope if needed\n",
        "import numpy as np  # Ensure numpy is imported\n",
        "\n",
        "print(\"\\n--- Loading saved model and predicting on dummy data ---\")\n",
        "# Assumes model_save_path is defined in Cell 10 and points to the correct saved file\n",
        "loaded_model = load_combined_model(model_save_path)\n",
        "\n",
        "if loaded_model:\n",
        "    # --- Define Dummy Data (including one with Same_Parents=1) ---\n",
        "    # Ensure keys match the column names in the *original X dataframe* (before FE/preprocessing)\n",
        "    dummy_data_list = [\n",
        "        # Dummy Entry 1 (Different Parents)\n",
        "        {\n",
        "            'Cow_Breed': 'Angus', 'Cow_Age': 5, 'Cow_Weight': 550.0, 'Cow_Height': 130.0,\n",
        "            'Cow_Milk_Yield': 8.5, 'Cow_Health_Status': 0, 'Cow_Genetic_Diversity_Score': 7.5,\n",
        "            'Cow_Fertility_Rate': 60.0, 'Cow_Breeding_Success_Rate': 50.0, 'Cow_Drought_Resistance': 70.0,\n",
        "            'Cow_Disease_Resistance_Score': 6.0, 'Cow_Market_Value': 15000, 'Cow_Temperament': 'Calm',\n",
        "            'Cow_Mother_Milk_Yield': 7.0, 'Cow_Disease': 'FootRot', 'Cow_Past_Breeding_Success': 'Moderate',\n",
        "            'Bull_Breed': 'Brahman', 'Bull_Age': 4, 'Bull_Weight': 650.0, 'Bull_Height': 145.0,\n",
        "            'Bull_Milk_Yield': np.nan, 'Bull_Health_Status': 0, 'Bull_Genetic_Diversity_Score': 8.0,\n",
        "            'Bull_Fertility_Rate': 70.0, 'Bull_Breeding_Success_Rate': 60.0, 'Bull_Drought_Resistance': 80.0,\n",
        "            'Bull_Disease_Resistance_Score': 7.5, 'Bull_Market_Value': 20000, 'Bull_Temperament': 'Aggressive',\n",
        "            'Bull_Mother_Milk_Yield': 8.8, 'Bull_Disease': 'None', 'Bull_Past_Breeding_Success': 'High',\n",
        "            # --- Top-level/Combined Features ---\n",
        "            'Same_Parents': 0, # Different parents\n",
        "            'Trait_Difference': 15,\n",
        "            'Genetic_Diversity': 8.1, # Example overall score\n",
        "            'Fertility_Rate': 65, # Example overall score\n",
        "            'Breeding_Success_Rate': 55, # Example overall score\n",
        "            'Disease_Resistance_Score': 6.8, # Example overall score\n",
        "            'Market_Value': 17500 # Example overall score - Note: Model might use Cow/Bull MV instead if selected\n",
        "        },\n",
        "        # Dummy Entry 2 (Same Parents)\n",
        "        {\n",
        "            'Cow_Breed': 'Holstein', 'Cow_Age': 7, 'Cow_Weight': 610.0, 'Cow_Height': 138.0,\n",
        "            'Cow_Milk_Yield': 7.0, 'Cow_Health_Status': 1, 'Cow_Genetic_Diversity_Score': 6.8,\n",
        "            'Cow_Fertility_Rate': 75.0, 'Cow_Breeding_Success_Rate': 65.0, 'Cow_Drought_Resistance': 55.0,\n",
        "            'Cow_Disease_Resistance_Score': 7.2, 'Cow_Market_Value': 21000, 'Cow_Temperament': 'Aggressive',\n",
        "            'Cow_Mother_Milk_Yield': 8.1, 'Cow_Disease': 'None', 'Cow_Past_Breeding_Success': 'High',\n",
        "            'Bull_Breed': 'Angus', 'Bull_Age': 6, 'Bull_Weight': 710.0, 'Bull_Height': 152.0,\n",
        "            'Bull_Milk_Yield': np.nan, 'Bull_Health_Status': 0, 'Bull_Genetic_Diversity_Score': 7.1,\n",
        "            'Bull_Fertility_Rate': 65.0, 'Bull_Breeding_Success_Rate': 55.0, 'Bull_Drought_Resistance': 60.0,\n",
        "            'Bull_Disease_Resistance_Score': 6.8, 'Bull_Market_Value': 19000, 'Bull_Temperament': 'Calm',\n",
        "            'Bull_Mother_Milk_Yield': 7.2, 'Bull_Disease': 'BLV', 'Bull_Past_Breeding_Success': 'Low',\n",
        "            # --- Top-level/Combined Features ---\n",
        "            'Same_Parents': 1, # Same parents\n",
        "            'Trait_Difference': 22,\n",
        "            'Genetic_Diversity': 6.5,\n",
        "            'Fertility_Rate': 70,\n",
        "            'Breeding_Success_Rate': 60,\n",
        "            'Disease_Resistance_Score': 7.0,\n",
        "            'Market_Value': 20000\n",
        "        },\n",
        "         # Dummy Entry 3 (Missing values test)\n",
        "        {\n",
        "            'Cow_Breed': 'Brahman', 'Cow_Age': 8, 'Cow_Weight': 580.0, 'Cow_Height': 135.0,\n",
        "            'Cow_Milk_Yield': np.nan, 'Cow_Health_Status': 0, 'Cow_Genetic_Diversity_Score': 7.0,\n",
        "            'Cow_Fertility_Rate': 55.0, 'Cow_Breeding_Success_Rate': 45.0, 'Cow_Drought_Resistance': 65.0,\n",
        "            'Cow_Disease_Resistance_Score': 5.5, 'Cow_Market_Value': 16000, 'Cow_Temperament': 'Calm',\n",
        "            'Cow_Mother_Milk_Yield': 6.5, 'Cow_Disease': np.nan, 'Cow_Past_Breeding_Success': 'Low',\n",
        "            'Bull_Breed': 'Gir', 'Bull_Age': 5, 'Bull_Weight': np.nan, 'Bull_Height': 148.0,\n",
        "            'Bull_Milk_Yield': np.nan, 'Bull_Health_Status': 1, 'Bull_Genetic_Diversity_Score': 7.9,\n",
        "            'Bull_Fertility_Rate': 72.0, 'Bull_Breeding_Success_Rate': 62.0, 'Bull_Drought_Resistance': 70.0,\n",
        "            'Bull_Disease_Resistance_Score': np.nan, 'Bull_Market_Value': 23000, 'Bull_Temperament': 'Calm',\n",
        "            'Bull_Mother_Milk_Yield': 8.0, 'Bull_Disease': 'None', 'Bull_Past_Breeding_Success': 'Moderate',\n",
        "            # --- Top-level/Combined Features ---\n",
        "            'Same_Parents': 0,\n",
        "            'Trait_Difference': np.nan,\n",
        "            'Genetic_Diversity': 7.2,\n",
        "            'Fertility_Rate': 63.5,\n",
        "            'Breeding_Success_Rate': 53.5,\n",
        "            'Disease_Resistance_Score': 6.0, # Example overall score\n",
        "            'Market_Value': 19500\n",
        "        }\n",
        "    ]\n",
        "    # Note: The Feature Engineered columns (FE_...) are NOT included here;\n",
        "    # they should be calculated from the base columns if needed by the model\n",
        "    # (They were added to X in Cell 4/5 before preprocessing in the training script)\n",
        "\n",
        "    # Create DataFrame from the list of dictionaries\n",
        "    combined_dummy_df = pd.DataFrame(dummy_data_list)\n",
        "    print(f\"Dummy data created. Shape: {combined_dummy_df.shape}\")\n",
        "\n",
        "    # --- Dynamically ensure all columns from training X are present ---\n",
        "    final_dummy_df = None # Initialize\n",
        "    if 'preprocessor' in loaded_model:\n",
        "        try:\n",
        "            # Get expected feature names from the fitted preprocessor\n",
        "            if hasattr(loaded_model['preprocessor'], 'feature_names_in_'):\n",
        "                expected_cols = loaded_model['preprocessor'].feature_names_in_\n",
        "            else:\n",
        "                 print(\"Warning: Cannot automatically determine expected columns from preprocessor. Using columns from Cell 4's X.\")\n",
        "                 if 'X' in globals(): expected_cols = list(X.columns)\n",
        "                 else: raise ValueError(\"Original X dataframe not available.\")\n",
        "\n",
        "            print(f\"\\nPreprocessor expects {len(expected_cols)} columns.\")\n",
        "            # print(\"Expected columns:\", expected_cols) # Uncomment to debug\n",
        "\n",
        "            # Check for missing columns in the combined dummy data\n",
        "            current_dummy_cols = combined_dummy_df.columns\n",
        "            missing_in_dummy = [col for col in expected_cols if col not in current_dummy_cols]\n",
        "            if missing_in_dummy:\n",
        "                print(f\"Adding missing expected columns to dummy data: {missing_in_dummy}\")\n",
        "                for col in missing_in_dummy:\n",
        "                    # Add missing columns with NaN (imputer will handle these)\n",
        "                    combined_dummy_df[col] = np.nan\n",
        "\n",
        "            # Ensure columns are in the correct order\n",
        "            try:\n",
        "                # Select only the expected columns in the correct order\n",
        "                final_dummy_df = combined_dummy_df[expected_cols]\n",
        "                print(\"Dummy data columns aligned with preprocessor expectations.\")\n",
        "                # print(\"Final dummy columns:\", final_dummy_df.columns.tolist()) # Uncomment to debug\n",
        "            except KeyError as e_key:\n",
        "                 print(f\"KeyError aligning dummy data columns: {e_key}. Check names.\")\n",
        "                 final_dummy_df = None\n",
        "            except Exception as e_align:\n",
        "                 print(f\"Error aligning dummy data columns: {e_align}\")\n",
        "                 final_dummy_df = None\n",
        "\n",
        "        except Exception as e_cols:\n",
        "             print(f\"Error preparing dummy data columns: {e_cols}\")\n",
        "             final_dummy_df = None\n",
        "    else:\n",
        "         print(\"ERROR: Preprocessor not found in loaded model components.\")\n",
        "         final_dummy_df = None\n",
        "\n",
        "    # --- Run Prediction if dummy data is ready ---\n",
        "    if final_dummy_df is not None:\n",
        "        predictions = predict_cattle_compatibility(final_dummy_df, loaded_model) # Use the final aligned df\n",
        "\n",
        "        if predictions:\n",
        "            print(\"\\n--- Predictions for Dummy Data ---\")\n",
        "            results_df = pd.DataFrame(predictions)\n",
        "            # Add index for clarity if needed\n",
        "            # results_df.index = [f\"Pair {i+1}\" for i in range(len(results_df))]\n",
        "            print(results_df.to_string()) # Print full DataFrame results\n",
        "        else:\n",
        "            print(\"Prediction function returned None (failed).\")\n",
        "    else:\n",
        "         print(\"Dummy data preparation failed, skipping prediction.\")\n",
        "\n",
        "else:\n",
        "    print(\"Could not load model components to run prediction example.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C07UTZNkBLZI",
        "outputId": "88593ae8-e983-4184-9304-83e1497d879d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Loading saved model and predicting on dummy data ---\n",
            "Model components loaded successfully from /content/drive/MyDrive/MyModels/cattle_predictor_v2.pkl\n",
            "Dummy data created. Shape: (3, 39)\n",
            "\n",
            "Preprocessor expects 34 columns.\n",
            "Adding missing expected columns to dummy data: ['Cow_Same_Parents', 'Bull_Same_Parents']\n",
            "Dummy data columns aligned with preprocessor expectations.\n",
            "\n",
            "--- Predictions for Dummy Data ---\n",
            "  Prediction  Confidence_Score_Percent  Raw_CCS_Score\n",
            "0        Yes                     59.70          30.60\n",
            "1        Yes                     57.22          27.25\n",
            "2        Yes                     55.90          25.47\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['Bull_Milk_Yield']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 11. Example Usage (with Multiple Added Sample Pairs)\n",
        "\n",
        "import pandas as pd # Ensure pandas is imported\n",
        "import numpy as np  # Ensure numpy is imported\n",
        "\n",
        "print(\"\\n--- Loading saved model and predicting on dummy data ---\")\n",
        "# Assumes model_save_path is defined in Cell 10 and points to the correct saved file\n",
        "loaded_model = load_combined_model(model_save_path)\n",
        "\n",
        "if loaded_model:\n",
        "    # --- Define the specific sample pairs ---\n",
        "\n",
        "    # Pair 1: \"Bad Pair\" (from previous request)\n",
        "    pair1_bad_data = {\n",
        "        'Cow_Breed': 'Sahiwal', 'Cow_Age': 4, 'Cow_Weight': 350, 'Cow_Height': 130,\n",
        "        'Cow_Milk_Yield': 4, 'Cow_Health_Status': 2, 'Cow_Temperament': 'Aggressive',\n",
        "        'Cow_Genetic_Diversity_Score': 3, 'Cow_Fertility_Rate': 50, 'Cow_Breeding_Success_Rate': 45,\n",
        "        'Cow_Drought_Resistance': 80, 'Cow_Disease_Resistance_Score': 4, 'Cow_Market_Value': 15000,\n",
        "        'Cow_Mother_Milk_Yield': np.nan, 'Cow_Disease': np.nan, 'Cow_Past_Breeding_Success': 'Low',\n",
        "        'Bull_Breed': 'Sahiwal', 'Bull_Age': 15, 'Bull_Weight': 550, 'Bull_Height': 160,\n",
        "        'Bull_Milk_Yield': np.nan, 'Bull_Health_Status': 1, 'Bull_Temperament': 'Aggressive',\n",
        "        'Bull_Mother_Milk_Yield': 3, 'Bull_Genetic_Diversity_Score': 3, 'Bull_Fertility_Rate': 50,\n",
        "        'Bull_Breeding_Success_Rate': 45, 'Bull_Drought_Resistance': 80,\n",
        "        'Bull_Disease_Resistance_Score': 4, 'Bull_Market_Value': 15000, 'Bull_Disease': np.nan,\n",
        "        'Bull_Past_Breeding_Success': 'Low',\n",
        "        'Same_Parents': 1, 'Trait_Difference': 40, 'Genetic_Diversity': 3, 'Fertility_Rate': 50,\n",
        "        'Breeding_Success_Rate': 45, 'Disease_Resistance_Score': 4, 'Market_Value': 15000,\n",
        "        'Past_Breeding_Success': 'Low'\n",
        "        # Add ALL other columns expected by X with np.nan if not specified above\n",
        "    }\n",
        "    pair1_df = pd.DataFrame([pair1_bad_data])\n",
        "\n",
        "    # Pair 2: Very Bad Pair (Same Parents, Sick, Low Stats)\n",
        "    pair2_data = {\n",
        "        'Cow_Breed': 'Jersey', 'Cow_Age': 3, 'Cow_Weight': 300, 'Cow_Height': 125,\n",
        "        'Cow_Milk_Yield': 3, 'Cow_Health_Status': 2, 'Cow_Temperament': 'Aggressive',\n",
        "        'Cow_Genetic_Diversity_Score': 2, 'Cow_Fertility_Rate': 45, 'Cow_Breeding_Success_Rate': 40,\n",
        "        'Cow_Drought_Resistance': 20, 'Cow_Disease_Resistance_Score': 3, 'Cow_Market_Value': 12000,\n",
        "        'Cow_Mother_Milk_Yield': np.nan, 'Cow_Disease': np.nan, 'Cow_Past_Breeding_Success': 'Low',\n",
        "        'Bull_Breed': 'Jersey', 'Bull_Age': 10, 'Bull_Weight': 500, 'Bull_Height': 155,\n",
        "        'Bull_Milk_Yield': np.nan, 'Bull_Health_Status': 2, 'Bull_Temperament': 'Aggressive',\n",
        "        'Bull_Mother_Milk_Yield': 4, 'Bull_Genetic_Diversity_Score': 2, 'Bull_Fertility_Rate': 45,\n",
        "        'Bull_Breeding_Success_Rate': 40, 'Bull_Drought_Resistance': 20,\n",
        "        'Bull_Disease_Resistance_Score': 3, 'Bull_Market_Value': 12000, 'Bull_Disease': np.nan,\n",
        "        'Bull_Past_Breeding_Success': 'Low',\n",
        "        'Same_Parents': 1, 'Trait_Difference': 35, 'Genetic_Diversity': 2, 'Fertility_Rate': 45,\n",
        "        'Breeding_Success_Rate': 40, 'Disease_Resistance_Score': 3, 'Market_Value': 12000,\n",
        "        'Past_Breeding_Success': 'Low'\n",
        "        # Add ALL other columns expected by X with np.nan if not specified above\n",
        "    }\n",
        "    pair2_df = pd.DataFrame([pair2_data])\n",
        "\n",
        "    # Pair 3: Different Parents, Mixed Health/Stats\n",
        "    pair3_data = {\n",
        "        'Cow_Breed': 'Holstein', 'Cow_Age': 7, 'Cow_Weight': 450, 'Cow_Height': 140,\n",
        "        'Cow_Milk_Yield': 6, 'Cow_Health_Status': 1, 'Cow_Temperament': 'Neutral', # Handle 'Neutral' if needed\n",
        "        'Cow_Genetic_Diversity_Score': 4, 'Cow_Fertility_Rate': 55, 'Cow_Breeding_Success_Rate': 35,\n",
        "        'Cow_Drought_Resistance': 80, 'Cow_Disease_Resistance_Score': 4, 'Cow_Market_Value': 18000,\n",
        "        'Cow_Mother_Milk_Yield': np.nan, 'Cow_Disease': np.nan, 'Cow_Past_Breeding_Success': 'Moderate',\n",
        "        'Bull_Breed': 'Gir', 'Bull_Age': 14, 'Bull_Weight': 700, 'Bull_Height': 175,\n",
        "        'Bull_Milk_Yield': np.nan, 'Bull_Health_Status': 2, 'Bull_Temperament': 'Aggressive',\n",
        "        'Bull_Mother_Milk_Yield': 4, 'Bull_Genetic_Diversity_Score': 4, 'Bull_Fertility_Rate': 55,\n",
        "        'Bull_Breeding_Success_Rate': 35, 'Bull_Drought_Resistance': 80,\n",
        "        'Bull_Disease_Resistance_Score': 4, 'Bull_Market_Value': 18000, 'Bull_Disease': np.nan,\n",
        "        'Bull_Past_Breeding_Success': 'Moderate',\n",
        "        'Same_Parents': 0, 'Trait_Difference': 32, 'Genetic_Diversity': 4, 'Fertility_Rate': 55,\n",
        "        'Breeding_Success_Rate': 35, 'Disease_Resistance_Score': 4, 'Market_Value': 18000,\n",
        "        'Past_Breeding_Success': 'Moderate'\n",
        "        # Add ALL other columns expected by X with np.nan if not specified above\n",
        "    }\n",
        "    # Handle 'Neutral' Temperament - map it to known category or NaN if encoder can't handle it\n",
        "    if 'Cow_Temperament' in pair3_data and pair3_data['Cow_Temperament'] == 'Neutral':\n",
        "        # Option 1: Map to 'Calm' or 'Aggressive' if appropriate\n",
        "        # pair3_data['Cow_Temperament'] = 'Calm'\n",
        "        # Option 2: Map to NaN so imputer makes it 'Missing'\n",
        "         pair3_data['Cow_Temperament'] = np.nan\n",
        "         print(\"Note: Mapping 'Neutral' temperament to NaN for preprocessing.\")\n",
        "\n",
        "    pair3_df = pd.DataFrame([pair3_data])\n",
        "\n",
        "\n",
        "    # --- Create original dummy data (from previous example, keep maybe 1 good one) ---\n",
        "    original_dummy_data_list = [\n",
        "        # Dummy Entry 1 (Good, Different Parents)\n",
        "        {\n",
        "            'Cow_Breed': 'Angus', 'Cow_Age': 5, 'Cow_Weight': 550.0, 'Cow_Height': 130.0,\n",
        "            'Cow_Milk_Yield': 8.5, 'Cow_Health_Status': 0, 'Cow_Genetic_Diversity_Score': 7.5,\n",
        "            'Cow_Fertility_Rate': 60.0, 'Cow_Breeding_Success_Rate': 50.0, 'Cow_Drought_Resistance': 70.0,\n",
        "            'Cow_Disease_Resistance_Score': 6.0, 'Cow_Market_Value': 15000, 'Cow_Temperament': 'Calm',\n",
        "            'Cow_Mother_Milk_Yield': 7.0, 'Cow_Disease': 'FootRot', 'Cow_Past_Breeding_Success': 'Moderate',\n",
        "            'Bull_Breed': 'Brahman', 'Bull_Age': 4, 'Bull_Weight': 650.0, 'Bull_Height': 145.0,\n",
        "            'Bull_Milk_Yield': np.nan, 'Bull_Health_Status': 0, 'Bull_Genetic_Diversity_Score': 8.0,\n",
        "            'Bull_Fertility_Rate': 70.0, 'Bull_Breeding_Success_Rate': 60.0, 'Bull_Drought_Resistance': 80.0,\n",
        "            'Bull_Disease_Resistance_Score': 7.5, 'Bull_Market_Value': 20000, 'Bull_Temperament': 'Aggressive',\n",
        "            'Bull_Mother_Milk_Yield': 8.8, 'Bull_Disease': 'None', 'Bull_Past_Breeding_Success': 'High',\n",
        "            'Same_Parents': 0, 'Trait_Difference': 15, 'Genetic_Diversity': 8.1, 'Fertility_Rate': 65,\n",
        "            'Breeding_Success_Rate': 55, 'Disease_Resistance_Score': 6.8, 'Market_Value': 17500,\n",
        "            'Past_Breeding_Success': 'Moderate'\n",
        "        },\n",
        "    ]\n",
        "    original_dummy_df = pd.DataFrame(original_dummy_data_list)\n",
        "\n",
        "    # --- Concatenate the original dummy data and the new sample pairs ---\n",
        "    combined_dummy_df = pd.concat([original_dummy_df, pair1_df, pair2_df, pair3_df], ignore_index=True)\n",
        "    print(f\"Combined dummy data shape (with all samples): {combined_dummy_df.shape}\")\n",
        "\n",
        "\n",
        "    # --- Dynamically ensure all columns from training X are present ---\n",
        "    final_dummy_df = None # Initialize\n",
        "    if 'preprocessor' in loaded_model:\n",
        "        try:\n",
        "            # Get expected feature names\n",
        "            if hasattr(loaded_model['preprocessor'], 'feature_names_in_'):\n",
        "                expected_cols = loaded_model['preprocessor'].feature_names_in_\n",
        "            else:\n",
        "                 print(\"Warning: Cannot determine expected columns. Using columns from Cell 4's X.\")\n",
        "                 if 'X' in globals(): expected_cols = list(X.columns)\n",
        "                 else: raise ValueError(\"Original X dataframe not available.\")\n",
        "\n",
        "            print(f\"\\nPreprocessor expects {len(expected_cols)} columns.\")\n",
        "\n",
        "            # Check for missing columns\n",
        "            current_dummy_cols = combined_dummy_df.columns\n",
        "            missing_in_dummy = [col for col in expected_cols if col not in current_dummy_cols]\n",
        "            if missing_in_dummy:\n",
        "                print(f\"Adding missing expected columns: {missing_in_dummy}\")\n",
        "                for col in missing_in_dummy:\n",
        "                    combined_dummy_df[col] = np.nan\n",
        "\n",
        "            # Align columns\n",
        "            try:\n",
        "                final_dummy_df = combined_dummy_df[expected_cols]\n",
        "                print(\"Dummy data columns aligned.\")\n",
        "            except KeyError as e_key:\n",
        "                 print(f\"KeyError aligning dummy data columns: {e_key}. Check names.\")\n",
        "                 final_dummy_df = None\n",
        "            except Exception as e_align:\n",
        "                 print(f\"Error aligning dummy data columns: {e_align}\")\n",
        "                 final_dummy_df = None\n",
        "        except Exception as e_cols:\n",
        "             print(f\"Error preparing dummy data columns: {e_cols}\")\n",
        "             final_dummy_df = None\n",
        "    else:\n",
        "         print(\"ERROR: Preprocessor not found in loaded model.\")\n",
        "         final_dummy_df = None\n",
        "\n",
        "    # --- Run Prediction ---\n",
        "    if final_dummy_df is not None:\n",
        "        predictions = predict_cattle_compatibility(final_dummy_df, loaded_model)\n",
        "\n",
        "        if predictions:\n",
        "            print(\"\\n--- Predictions for Dummy Data (including added samples) ---\")\n",
        "            results_df = pd.DataFrame(predictions)\n",
        "            # Add labels to identify the pairs\n",
        "            num_original = len(original_dummy_df)\n",
        "            num_pair1 = len(pair1_df)\n",
        "            num_pair2 = len(pair2_df)\n",
        "            num_pair3 = len(pair3_df) # Should be 1\n",
        "            labels = (['Original Dummy'] * num_original +\n",
        "                      ['Bad Pair 1'] * num_pair1 +\n",
        "                      ['Bad Pair 2 (Same Parent)'] * num_pair2 +\n",
        "                      ['Mixed Pair 3'] * num_pair3)\n",
        "            results_df['Source'] = labels[:len(results_df)] # Ensure labels match length\n",
        "\n",
        "            print(results_df.to_string())\n",
        "        else:\n",
        "            print(\"Prediction function returned None (failed).\")\n",
        "    else:\n",
        "         print(\"Dummy data preparation failed.\")\n",
        "\n",
        "else:\n",
        "    print(\"Could not load model components.\")"
      ],
      "metadata": {
        "id": "8B4FE_N-DSXd",
        "outputId": "c523b4d9-f2cb-4ebb-e6e2-b96ea5fdb0e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Loading saved model and predicting on dummy data ---\n",
            "Model components loaded successfully from /content/drive/MyDrive/MyModels/cattle_predictor_v2.pkl\n",
            "Note: Mapping 'Neutral' temperament to NaN for preprocessing.\n",
            "Combined dummy data shape (with all samples): (4, 40)\n",
            "\n",
            "Preprocessor expects 34 columns.\n",
            "Adding missing expected columns: ['Cow_Same_Parents', 'Bull_Same_Parents']\n",
            "Dummy data columns aligned.\n",
            "\n",
            "--- Predictions for Dummy Data (including added samples) ---\n",
            "  Prediction  Confidence_Score_Percent  Raw_CCS_Score                    Source\n",
            "0        Yes                     59.70          30.60            Original Dummy\n",
            "1         No                     50.08          17.61                Bad Pair 1\n",
            "2         No                     51.06          18.93  Bad Pair 2 (Same Parent)\n",
            "3         No                     50.83          18.62              Mixed Pair 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['Bull_Milk_Yield']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}